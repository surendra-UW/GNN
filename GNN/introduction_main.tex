\section{Introduction}

%Neural Networks have been ubiquitous in the areas of pattern recognition, data prediction and crunching knowledge into embeddings. 
Graph Neural Networks (GNN) can be thought as a subset of neural networks which are modelled as graphs. Graphs are non-euclidean data structures where objects are represented as nodes and their relationship is captured as edges. GNN has vast uses cases because there are many datasets which are naturally expressed as graphs, like social media networks, molecules, DNA, internet traffic, knowledge graphs and more.

Historically, Convolutional Neural Networks (CNN) have been highly successful in extracting the spacial features from images and n-D euclidean data structures, but they struggle to capture the relationship present between the nodes as graph can have irregular structures and unequal number of neighbours making convolution operation difficult. 


GNNs can be broadly categorized into 4 types:
\begin{itemize}
    \item Recurrent GNN
    \item Graph Convolutional Neural Networks
    \item Graph Autoencoders (Attension Networks)
    \item Spatial-temporal Graphs (Recursive Networks)
\end{itemize}